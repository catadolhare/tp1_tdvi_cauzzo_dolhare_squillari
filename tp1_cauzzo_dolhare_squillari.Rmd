---
title: "TP1"
author: "Catalina Dolhare, Camila Cauzzo, Renata Squillari"
date: "`r Sys.Date()`"
output:
  word_document: default
  pdf_document: default
---

# 1. Introducción al problema

El siguiente conjunto de datos presenta información acerca de una encuesta de satisfacción a pasageros de una cierta aerolinea. Obtuvimos este dataset de Kaggle[^1], el cual cuenta con un conjunto de train con 104000 datos, representando el 80% del data set, y un conjunto de test con 26000 datos, representando el 20% del data set. Este data set cuenta con 23 variables, como "Type of travel", "Class", "Flight distance", "Departure Delay in Minutes", "Arrival Delay in Minutes". Principalmente, cuenta con "Satisfaction", variable categorica que puede tomar dos opciones: "Satisfaction" o "neutral or dissatisfaction".Con toda esta información, intentaremos predecir la satisfacción de un pasajero dado las respuesta a las variables.

Utilizamos este conjunto de datos dado que contiene diversas variables predictoras y no tiene un gran numero de datos faltantes (solo se encuentran datos faltas en una de las variables), por lo que podremos predecir un buen modelo.

Para el siguiente trabajo se necesitan importar las siguientes librerias:
```{r}
#install.packages("ggplot2")
#install.packages("corrplot")
#install.packages("MLmetrics")

library(ggplot2)
library(corrplot)
library(rpart)
library(rpart.plot)
library(MLmetrics)
```


# 2. Preparación de los datos

Como nuestro data set venia con dos conjuntos de datos que sumaban un total de aproximadamente 130.000 observaciones, decidimos juntar todos los datos y elegir aleatoriamente 50.000 datos. Para hacer esto y que sea repicable los datos que se eligan, utilizamos una semilla.
```{r}
datos_train <- read.csv("train.csv")
datos_test <- read.csv("test.csv")
```

```{r}
datos<-rbind(datos_train, datos_test)
```

```{r}
set.seed(123)
sample_datos <- datos[sample(nrow(datos), 50000),]
nrow(sample_datos)
```

Para la variable satisfaction, que es lo que queremos predecir, originalmente era categorica, pero decidimos transformarla en numerica donde satisfied = 1 y neutral o disatisfied = 0. Esto lo hicimos para poder analizar graficamente las variables predictoras contra satisfaction, dado que no podiamos realizarlo si esta era categorica.
```{r}
sample_datos$satisfaction <- as.numeric(as.factor(sample_datos$satisfaction)) - 1
```

Para poder ver las estadisticas descriptivas de las varibales, realizamos un summary de los datos. Este nos provee el minimo, los quartiles, la media, la mediana y el maximo de las variables numericas.

```{r}
summary(sample_datos)

```
A simple vista, vemos en la variable de satisfaction una mediana de 0 y una media 0.4338. Esto nos indica que hay mas pasajeros insatisfechos (0) que satisfechos (1).

Por otro lado, notamos que las variables que tiene una escala de 0 a 5 tiene mediana y media en aproximadamente 3, esto significa que en su mayoria las personas se encuentran indiferente dentro de cada categoría.

Para ver si las otras variables predictoras influyen en satisfacion hicimos una matriz de correlacion. Sabemos que correlacion no implica causalidad, no obstante, es bueno para visualizar y descartar variables que no influyen directamente en la satisfación de los pasajeros.
```{r, echo=FALSE}
numeric_data <- sample_datos[, sapply(sample_datos, is.numeric)]
cor_matrix <- cor(numeric_data)
corrplot(cor_matrix, method = "color", 
         tl.col = "black", tl.srt = 45, tl.cex = 0.5,  # Ajustes de etiquetas
         cl.ratio = 0.2,  # Ajustar el tamaño de las celdas
         addgrid.col = "black", # Añadir color a las líneas de la cuadrícula
         addCoef.col = "black",
         number.cex = 0.3)  
```
Se puede ver que hay algunas variables que no tienen correlación con la satisfación, y son "departure arrival time convenient", "gate of location", "departure delay in minutes", "departure arrival in minutes". Como no podemos descartar que no haya causalidad, analizamos estas variables para ver si inciden sobre la satisfación. 
```{r, echo=FALSE}
par(mfrow = c(1, 2), mar = c(5, 5, 4, 2), cex = 1.2)

# Filtrar los datos por nivel de satisfacción
delay_satisfecho <- sample_datos$Departure.Delay.in.Minutes[sample_datos$satisfaction == 1]
delay_insatisfecho <- sample_datos$Departure.Delay.in.Minutes[sample_datos$satisfaction == 0]

density_satisfecho <- density(delay_satisfecho, na.rm = TRUE)
density_insatisfecho <- density(delay_insatisfecho, na.rm = TRUE)

# Crear el gráfico
plot(density_satisfecho, 
     main = "Comparación de Densidades de Retrasos por Satisfacción", 
     xlab = "Departure Delay in Minutes", 
     ylab = "Density", 
     col = "red", 
     lwd = 2, 
     xlim = c(0, max(c(delay_satisfecho, delay_insatisfecho), na.rm = TRUE)))

# Agregar la densidad del grupo insatisfecho
lines(density_insatisfecho, col = "blue", lwd = 2)

# Agregar leyenda
legend("topright", 
       legend = c("Satisfechos", "Insatisfechos"), 
       col = c("red", "blue"), 
       lwd = 2)
```

```{r, echo=FALSE}
par(mfrow = c(1, 2), mar = c(5, 5, 4, 2), cex = 1.2)

# Filtrar los datos por nivel de satisfacción
arrival_satisfecho <- sample_datos$Arrival.Delay.in.Minutes[sample_datos$satisfaction == 1]
arrival_insatisfecho <- sample_datos$Arrival.Delay.in.Minutes[sample_datos$satisfaction == 0]

hist(arrival_satisfecho, 
     probability = TRUE, 
     main = "Satisfechos", 
     xlab = "Arrival Delay in Minutes", 
     xlim = c(0, max(sample_datos$Arrival.Delay.in.Minutes, na.rm = TRUE)), 
     ylim = c(0, 0.04), 
     col = "red", 
     border = "black")

# Histograma para los clientes insatisfechos
hist(arrival_insatisfecho, 
     probability = TRUE, 
     main = "Insatisfechos", 
     xlab = "Arrival Delay in Minutes", 
     xlim = c(0, max(sample_datos$Arrival.Delay.in.Minutes, na.rm = TRUE)), 
     ylim = c(0, 0.04), 
     col = "blue", 
     border = "black")
```

En cuanto a ambos delays, notamos que no afectan a la satisfacción de una persona, dado que la distribución es muy similar entre los satisfechos y no satisfechos.

```{r, echo=FALSE}
par(mfrow = c(1, 2), mar = c(5, 5, 4, 2), cex = 1.2)

# Filtrar los datos por nivel de satisfacción
departure_arrival_satisfecho <- sample_datos$Departure.Arrival.time.convenient[sample_datos$satisfaction == 1]
departure_arrival_insatisfecho <- sample_datos$Departure.Arrival.time.convenient[sample_datos$satisfaction == 0]

hist(departure_arrival_satisfecho, 
     probability = TRUE, 
     main = "Satisfechos", 
     xlab = "Departure arrival time convenient", 
     xlim = c(0, max(sample_datos$Departure.Arrival.time.convenient, na.rm = TRUE)), 
     ylim = c(0, 1), 
     col = "red", 
     border = "black")

# Histograma para los clientes insatisfechos
hist(departure_arrival_insatisfecho, 
     probability = TRUE, 
     main = "Insatisfechos", 
     xlab = "Departure arrival time convenient", 
     xlim = c(0, max(sample_datos$Departure.Arrival.time.convenient, na.rm = TRUE)), 
     ylim = c(0, 1), 
     col = "blue", 
     border = "black")
```

```{r, echo=FALSE}
par(mfrow = c(1, 2), mar = c(5, 5, 4, 2), cex = 1.2)

# Filtrar los datos por nivel de satisfacción
gate_satisfecho <- sample_datos$Gate.location[sample_datos$satisfaction == 1]
gate_insatisfecho <- sample_datos$Gate.location[sample_datos$satisfaction == 0]

hist(gate_satisfecho, 
     probability = TRUE, 
     main = "Satisfechos", 
     xlab = "Gate location", 
     xlim = c(0, max(sample_datos$Departure.Arrival.time.convenient, na.rm = TRUE)), 
     ylim = c(0, 2), 
     col = "red", 
     border = "black")

# Histograma para los clientes insatisfechos
hist(gate_insatisfecho, 
     probability = TRUE, 
     main = "Insatisfechos", 
     xlab = "Gate location", 
     xlim = c(0, max(sample_datos$Departure.Arrival.time.convenient, na.rm = TRUE)), 
     ylim = c(0, 2), 
     col = "blue", 
     border = "black")
```
Al graficar estas 4 variables, podemos ver que la ditribución entre pasajeros satisfechos e insatisfechos es muy similar por lo que concluimos que no impactan en lo que queremos predecir.

Por la misma razon de que correlación on implica causalidad, decidimos probar en algunas variables si existia este tipo de relación. El siguiente grafico muestra la relación entre la variable "Type of Travel" y "satisfaction":
```{r, echo=FALSE}
library(ggplot2)
ggplot(data = sample_datos) +
  geom_histogram(mapping = aes(x = satisfaction, fill = Type.of.Travel),
                 colour = "black", binwidth = 0.5) +
  scale_fill_viridis_d() +
  facet_wrap(~ Type.of.Travel)
```
En este, podemos ver que existe una clara división entre el tipo de viaje. Podemos concluir que las personas que viajan por placer o temas personales suelen estar más insatisfechos que los que viajan por negocios. Viendo la distribución podemos ver que es una variable que realmente influye en lo que queremos predecir. 

En el siguiente histograma, queremos demostrar la relación entre la variable "Online boarding" y "satisfaction".
```{r, echo=FALSE}
par(mfrow = c(1, 2), mar = c(5, 5, 4, 2), cex = 1.2)

# Filtrar los datos por nivel de satisfacción
onlineb_satisfecho <- sample_datos$Online.boarding[sample_datos$satisfaction == 1]
onlineb_insatisfecho <- sample_datos$Online.boarding[sample_datos$satisfaction == 0]

hist(onlineb_satisfecho, 
     probability = TRUE, 
     main = "Satisfechos", 
     xlab = "Online boarding", 
     xlim = c(0, max(sample_datos$Online.boarding, na.rm = TRUE)), 
     ylim = c(0, 1), 
     col = "pink", 
     border = "black")

# Histograma para los clientes insatisfechos
hist(onlineb_insatisfecho, 
     probability = TRUE, 
     main = "Insatisfechos", 
     xlab = "Online boarding", 
     xlim = c(0, max(sample_datos$Online.boarding, na.rm = TRUE)), 
     ylim = c(0, 1), 
     col = "green", 
     border = "black")
```
Vemos que las distribuciones entre ambos son diferentes por lo que entendemos a "online boarding" como una variable influyente en la satisfacción del pasajero. Tiene sentido el grafico ya que los pasajeros satisfechos puntuan con una nota alta el online boarding mientras que los pasajeros insatisfechos puntuan con una nota más baja.

# 3. Construcción de un árbol de decisión básico

Para construir el arbol, dividimos nuestro conjunto de datos en entrenamiento, con 70% de los datos, validación, con 15% de los datos, y testo, con 15% de los datos. Como nuestro sample de datos ya fue elegido al azar de un conjunto más grande, simplemente podemos dividir entre los respectivos porcentajes y nos seguiremos garantizando que sea aleatorio.

```{r}
entrenamiento <- sample_datos[1:35000,]
validacion <- sample_datos[35001:42500,]
testeo <- sample_datos[42501:50000,]

nrow(entrenamiento)
nrow(validacion)
nrow(testeo)
```

Con la librería rpart generamos un arbol de decision a partir de los datos de entrenamiento, utilizando los hiperparamentros por defecto.

```{r}
tree <- rpart(formula = satisfaction ~ ., 
              data = entrenamiento, 
              method = "class")
tree$control
```

Dentro de los hiperparametros que toma el árbol por defecto nos encontramos que minsplit toma por defecto el valor de 20. Esto quiere decir que el numero minimo de observaciones que se necesita para dividir un nodo intermedio es de 20.

En cuanto a minbucket, este toma un valor de 7. Lo que refiere a que se necesita un minimo de 7 observaciones en cada hoja de un arbol. Esto evita que las hojas del arbol tenga muy pocas observaciones y logra que no tengamos un modelo overfitted. 

El hiperparametro cp, es el parametro de complejidad para la poda del arbol. Es de 0.01 por lo que significa que una división en el arbol debe reducir el error en al menos 1% para ser considerada util. 

Maxdepth es la maxima produnfidad permitida para la construcción del árbol y en este caso, puede tener hasta 30 niveles. Si bien cuanto más grande el árbol mejor se ajusta a los datos, si el arbol es muy profundo, se puede generar overfitting. 

Por ultimo, xval toma un valor de 10, por lo que se utilizaran 10 grupos para validación cruzada. Un mayor valor de xval te asegura una estimación más precisa pero mayor tiempo de computo.

```{r}
rpart.plot(tree)
```

En general, cada nodo cuenta con el porcentaje de datos que caen en ese nodo del total, la proporción de datos que corresponden con un dato satisfecho (satisfied = 1) y el color del nodo indica la pureza del mismo.

En el nodo raiz encontramos el 100% de los datos, de los cuales el 44% se corresponde con pasajeros satisfechos. El color del nodo no es tan intenso, dado que en este se encuentran todos los datos, los satisfechos como los insatisfecho. Como la clase predominante es insatisfecho, el nodo contiene un 0. 

El factor mas importante para determinar la satisfacción del pasajero es el online boarding. Este divide a los datos exactamente a la mitad dependiendo de si toman un valor <4. Si esto es asi, toman la rama de la izquierda, y si no, la de la derecha. 

Por la rama de la izquierda, se encuentra un nodo donde predomina la insatisfacción, al tener 0.15 de los datos satisfechos. En este podemos ver un color más puro en comparación al nodo raiz.

Caen en dos nodos diferentes, donde uno predomina la insatisfacción al tener 15% de satisfacción y en el otro predomina la satisfaccion ya que tiene un nivel del 72%. Para el lado de insatisfacción podemos ver que inflight wifi service vuelve a dividir los datos y si es >4 cae en una hoja terminal en el cual los datos que caen alli son satisfechos. Vemos que el color no es muy puro pero si los datos caen allí lo predecira como un pasajero satisfecho. En caso contrario, cae en otro nodo que predominan los insatisfechos y los vuelve a dividir inflight wifi service >=1. Si cae allí, se predecira que el pasajero esta insatisfecho ya que solo 7% son satisfechos y predomina la clase de insatisfechos. El color del bodo nos muestra que es un nodo puro y el 44% de los datos de entrenamiento van a caer allí. Caso contrario, caerá en un nodo que predecirá al pasajero como satisfecho. Este es un nodo es completamente puro ya que el 100% de los datos que caen aca son satisfechos. 

Volviendo a la rama en donde el online boarding >4, la otra mitad de los datos caen en un primer nodo que predomina la satisfacción y luego los divide por Inflight entertainment. Si esta es <4, caen en un nodo donde predomina la clase insatisfecha y los divide por inflight wifi service. Si es >=5 cae en una hoja terminal de color muy puro ya que el 100% de los datos de entrenamiento que caen aca son pasajeros satisfechos. Si el inflight wifi service <5, cae en otro nodo que se divide por inflight wifi service >=1, cae en insatisfecho ya que solo el 34% de los datos son de pasajeros satisfechos. Sino, cae en un nodo completamente puro ya que el 100% de los datos son satisfechos.

Si el inflight entertainment es <=4, cae en un nodo donde predomina la clase satisfecha y de allí los divide por la variable leg room service. Si esta es >=4, cae en una hoja terminal en la que predomina la clase satisfecha. Esta hoja es de un color mayoritariamente puro ya que el 91% de los datos que caen aqui son de pasajeros satisfechos. Por el otro lado, si el leg room service <4 cae en un nodo donde mayoritariamente son pasajeros satisfechos. No obstante no es un nodo de color puro por lo que no se puede predecir con exactitud la conformidad del pasajero en cuanto al servicio brindado por la aerolinea. Asimismo, en este nodo se evalua que la varibale food and drink. Si esta es de <4, cae en una hoja terminal que no tiene un color puro porque solamente el 8% de los pasajeros estan satisfechos. Por ultimo, si food and drink >=4, cae en una hoja terminal no tan pura pero que predice como satisfechos el 71% de los pasajeros.

**4. Evaluación del árbol de decisión básico**

```{r}
predictions_clase <- predict(tree, newdata = testeo, type = "class")
predictions_prob <- predict(tree, newdata = testeo, type = "prob")
```

```{r}
ConfusionMatrix(y_pred = predictions_clase, y_true = testeo$satisfaction)
```
```{r}
Accuracy(y_pred = predictions_clase, y_true = testeo$satisfaction)
```
```{r}
Precision(y_pred = predictions_clase, y_true = testeo$satisfaction)
```
```{r}
Recall(y_pred = predictions_clase, y_true = testeo$satisfaction)
```
```{r}
F1_Score(y_pred = predictions_clase, y_true = testeo$satisfaction)
```
```{r}
AUC(y_pred = predictions_clase, y_true = testeo$satisfaction)
```

**5. Optimización del modelo**
```{r}
valores_maxdepth <- c(2, 5, 7, 10, 12, 15)
valores_minsplit <- c(15, 20, 25, 30, 35)
valores_minbucket <- c(10, 20, 30, 40, 50)
```
```{r}
buscar_hiperparametros <- function(entrenamiento, validacion, valores_maxdepth, valores_minsplit, valores_minbucket){
  valores_auc <- c()
  best_auc <- 0
  best_params <- c()
  for (i in 1:length(valores_maxdepth)){
    for (j in 1:length(valores_minsplit)){
      for (l in 1:length(valores_minbucket)){
        tree2 <- rpart(formula = satisfaction ~ ., 
                data = entrenamiento, 
                method = "class",
                control = rpart.control(maxdepth = valores_maxdepth[i], minsplit = valores_minsplit[j], minbucket = valores_minbucket[l], cp = 0, xval = 0))
      
        predicciones <- predict(tree2, newdata = validacion, type = "class")
        auc <- AUC(y_pred = datos$predicciones, y_true = datos$validation_satisfaction)
        valores_auc <- c(valores_auc, auc)
      
        if (!is.na(auc) && auc > best_auc){
          best_auc <- auc
          best_params <- c(valores_maxdepth[i], valores_minsplit[j], valores_minbucket[l])
        }
      }
    }
  }
  return (list(valores_auc = valores_auc, best_auc = best_auc, best_params = best_params))
}

```
```{r}
best <- buscar_hiperparametros(entrenamiento = entrenamiento, validacion = validacion, valores_maxdepth = valores_maxdepth, valores_minsplit = valores_minsplit, valores_minbucket = valores_minbucket)
best$valores_auc
best$best_auc
best$best_params
```
```{r}
best_tree <- rpart(formula = satisfaction ~ ., 
              data = entrenamiento, 
              method = "class",
              control = rpart.control(maxdepth = best$best_params[1], minsplit = best$best_params[2], minbucket = best$best_params[3], cp = 0, xval = 0))
best_predicciones <- predict(best_tree, newdata = validacion, type = "class")
AUC(y_pred = best_predicciones, y_true = testeo$satisfaction)
```

**6. Interpretación de resultados**
```{r}
rpart.plot(best_tree)
```
```{r}
importancia_variables <- best_tree$variable.importance

importancia_variables
```
```{r}
valores_maxdepth2 <- c(10, 15, 20, 25, 30)
valores_minsplit2 <- c(10, 20, 30, 40, 50)
valores_minbucket2 <- c(100, 200, 300, 400, 500)
```
```{r}
best2 <- buscar_hiperparametros(entrenamiento = entrenamiento, validacion = validacion, valores_maxdepth = valores_maxdepth2, valores_minsplit = valores_minsplit2, valores_minbucket = valores_minbucket2)
best2$valores_auc
best2$best_auc
best2$best_params 
```
```{r}
best_tree2 <- rpart(formula = satisfaction ~ ., 
              data = entrenamiento, 
              method = "class",
              control = rpart.control(maxdepth = best2$best_params[1], minsplit = best2$best_params[2], minbucket = best2$best_params[3], cp = 0, xval = 0))
best_predicciones <- predict(best_tree2, newdata = validacion, type = "class")
AUC(y_pred = best_predicciones, y_true = testeo$satisfaction)
```
```{r}
rpart.plot(best_tree2)
```
```{r}
valores_minbucket3 <- c(1000, 2000, 3000, 4000, 5000)
```
```{r}
best3 <- buscar_hiperparametros(entrenamiento = entrenamiento, validacion = validacion, valores_maxdepth = valores_maxdepth2, valores_minsplit = valores_minsplit2, valores_minbucket = valores_minbucket3)
best3$valores_auc
best3$best_auc
best3$best_params 
```
```{r}
best_tree3 <- rpart(formula = satisfaction ~ Flight.Distance + Inflight.wifi.service + Ease.of.Online.booking + Food.and.drink + Online.boarding + Seat.comfort + Inflight.entertainment + On.board.service + Leg.room.service + Baggage.handling + Checkin.service + Inflight.service + Cleanliness, 
              data = entrenamiento, 
              method = "class",
              control = rpart.control(maxdepth = best2$best_params[1], minsplit = best2$best_params[2], minbucket = best2$best_params[3], cp = 0, xval = 0))
best_predicciones <- predict(best_tree2, newdata = validacion, type = "class")
AUC(y_pred = best_predicciones, y_true = testeo$satisfaction)
```
```{r}
rpart.plot(best_tree2)
```
**7. Análisis del impacto de los valores faltantes**
```{r}
reemplazar_na <- function(data, porcentaje_na) {
  total_filas <- nrow(data)
  total_columnas <- ncol(data)  # Número total de columnas

  for (i in 1:(total_columnas - 1)) {  # Iterar hasta la anteúltima columna
    col <- colnames(data)[i]
    
    # Contar el número actual de NA en la columna
    na_existentes <- sum(is.na(data[[col]]))
    
    # Calcular cuántos NA totales debería haber para alcanzar el porcentaje deseado
    num_na_deseado <- round(porcentaje_na * total_filas)
    
    nuevos_na <- num_na_deseado - na_existentes
    
    # Solo agregar nuevos NA si el número necesario es positivo
    if (nuevos_na > 0) {
      na_indices <- sample(which(!is.na(data[[col]])), size = nuevos_na)
      data[na_indices, col] <- NA
    }
  }
  return(data)
}
```
```{r}
entrenamiento_na_20 <- reemplazar_na(entrenamiento, 0.20)
validacion_na_20 <- reemplazar_na(validacion, 0.20)
testeo_na_20 <- reemplazar_na(testeo, 0.01)

entrenamiento_na_50 <- reemplazar_na(entrenamiento, 0.50)
validacion_na_50 <- reemplazar_na(validacion, 0.50)
testeo_na_50 <- reemplazar_na(testeo, 0.50)

entrenamiento_na_75 <- reemplazar_na(entrenamiento, 0.75)
validacion_na_75 <- reemplazar_na(validacion, 0.75)
testeo_na_75 <- reemplazar_na(testeo, 0.75)
```
```{r}
best_na_20 <- buscar_hiperparametros(entrenamiento = entrenamiento_na_20, validacion = validacion_na_20, valores_maxdepth = valores_maxdepth2, valores_minsplit = valores_minsplit2, valores_minbucket = valores_minbucket2)

best_na_20$valores_auc
best_na_20$best_auc
best_na_20$best_params
```
```{r}
best_tree4 <- rpart(formula = satisfaction ~ Flight.Distance + Inflight.wifi.service + Ease.of.Online.booking + Food.and.drink + Online.boarding + Seat.comfort + Inflight.entertainment + On.board.service + Leg.room.service + Baggage.handling + Checkin.service + Inflight.service + Cleanliness, 
              data = entrenamiento_na_20, 
              method = "class")
best_tree4

best_predicciones <- predict(best_tree4, newdata = validacion_na_20, type = "class")
AUC(y_pred = best_predicciones, y_true = testeo_na_20$satisfaction)
```
```{r}
best_na_50 <- buscar_hiperparametros(entrenamiento = entrenamiento_na_50, validacion = validacion_na_50, valores_maxdepth = valores_maxdepth, valores_minsplit = valores_minsplit, valores_minbucket = valores_minbucket)


best_na_50$valores_auc
best_na_50$best_auc
best_na_50$best_params
```
```{r}
best_na_75 <- buscar_hiperparametros(entrenamiento = entrenamiento_na_75, validacion = validacion_na_75, valores_maxdepth = valores_maxdepth, valores_minsplit = valores_minsplit, valores_minbucket = valores_minbucket)

best_na_75$valores_auc
best_na_75$best_auc
best_na_75$best_params
```

[^1]: https://www.kaggle.com/datasets/teejmahal20/airline-passenger-satisfaction