---
title: "TP1"
author: "Catalina Dolhare, Camila Cauzzo, Renata Squillari"
date: "`r Sys.Date()`"
output:
  word_document: default
  pdf_document: default
---

# 1. Introducción al problema

El siguiente conjunto de datos presenta información acerca de una encuesta de satisfacción a pasageros de una cierta aerolinea. Obtuvimos este dataset de Kaggle[^1], el cual cuenta con un conjunto de train con 104000 datos, representando el 80% del data set, y un conjunto de test con 26000 datos, representando el 20% del data set. Este data set cuenta con 23 variables, como "Type of travel", "Class", "Flight distance", "Departure Delay in Minutes", "Arrival Delay in Minutes". Principalmente, cuenta con "Satisfaction", variable categorica que puede tomar dos opciones: "Satisfaction" o "neutral or dissatisfaction".Con toda esta información, intentaremos predecir la satisfacción de un pasajero dado las respuesta a las variables.

Utilizamos este conjunto de datos dado que contiene diversas variables predictoras y no tiene un gran numero de datos faltantes (solo se encuentran datos faltas en una de las variables), por lo que podremos predecir un buen modelo.

Para el siguiente trabajo se necesitan importar las siguientes librerias:
```{r}
#install.packages("ggplot2")
#install.packages("corrplot")
#install.packages("MLmetrics")

library(ggplot2)
library(corrplot)
library(rpart)
library(rpart.plot)
library(MLmetrics)
library(ROCR)
```


# 2. Preparación de los datos

Como nuestro data set venia con dos conjuntos de datos que sumaban un total de aproximadamente 130.000 observaciones, decidimos juntar todos los datos y elegir aleatoriamente 50.000 datos. Para hacer esto y que sea repicable los datos que se eligan, utilizamos una semilla.
```{r}
datos_train <- read.csv("train.csv")
datos_test <- read.csv("test.csv")
```

```{r}
datos<-rbind(datos_train, datos_test)
```

```{r}
set.seed(123)
sample_datos <- datos[sample(nrow(datos), 50000),]
nrow(sample_datos)
```

Para la variable satisfaction, que es lo que queremos predecir, originalmente era categorica, pero decidimos transformarla en numerica donde satisfied = 1 y neutral o disatisfied = 0. Esto lo hicimos para poder analizar graficamente las variables predictoras contra satisfaction, dado que no podiamos realizarlo si esta era categorica.
```{r}
sample_datos$satisfaction <- as.numeric(as.factor(sample_datos$satisfaction)) - 1
```

Para poder ver las estadisticas descriptivas de las varibales, realizamos un summary de los datos. Este nos provee el minimo, los quartiles, la media, la mediana y el maximo de las variables numericas.

```{r}
summary(sample_datos)

```
A simple vista, vemos en la variable de satisfaction una mediana de 0 y una media 0.4338. Esto nos indica que hay mas pasajeros insatisfechos (0) que satisfechos (1).

Por otro lado, notamos que las variables que tiene una escala de 0 a 5 tiene mediana y media en aproximadamente 3, esto significa que en su mayoria las personas se encuentran indiferente dentro de cada categoría.

Para ver si las otras variables predictoras influyen en satisfacion hicimos una matriz de correlacion. Sabemos que correlacion no implica causalidad, no obstante, es bueno para visualizar y descartar variables que no influyen directamente en la satisfación de los pasajeros.
```{r, echo=FALSE}
numeric_data <- sample_datos[, sapply(sample_datos, is.numeric)]
cor_matrix <- cor(numeric_data)
corrplot(cor_matrix, method = "color", 
         tl.col = "black", tl.srt = 45, tl.cex = 0.5,  # Ajustes de etiquetas
         cl.ratio = 0.2,  # Ajustar el tamaño de las celdas
         addgrid.col = "black", # Añadir color a las líneas de la cuadrícula
         addCoef.col = "black",
         number.cex = 0.3)  
```
Se puede ver que hay algunas variables que no tienen correlación con la satisfación, y son "departure arrival time convenient", "gate of location", "departure delay in minutes", "departure arrival in minutes". Como no podemos descartar que no haya causalidad, analizamos estas variables para ver si inciden sobre la satisfación. 
```{r, echo=FALSE}
delay_satisfecho <- sample_datos$Departure.Arrival.time.convenient[sample_datos$satisfaction == 1]
delay_insatisfecho <- sample_datos$Departure.Arrival.time.convenient[sample_datos$satisfaction == 0]

density_satisfecho <- density(delay_satisfecho, na.rm = TRUE)
density_insatisfecho <- density(delay_insatisfecho, na.rm = TRUE)

# Crear el gráfico
plot(density_satisfecho, 
     main = "Comparación de Densidades de Retrasos por Satisfacción", 
     xlab = "Departure Arrival Time Convenient", 
     ylab = "Density", 
     col = "red", 
     lwd = 2, 
     xlim = c(0, 5))

polygon(density_satisfecho, col = rgb(1, 0, 0, 0.5), border = "red")

# Rellenar la densidad para el grupo insatisfecho
polygon(density_insatisfecho, col = rgb(0, 0, 1, 0.5), border = "blue")

# Agregar leyenda
legend("topright", 
       legend = c("Satisfechos", "Insatisfechos"), 
       fill = c(rgb(1, 0, 0, 0.5), rgb(0, 0, 1, 0.5)))
```

Por la misma razon de que correlación on implica causalidad, decidimos probar en algunas variables si existia este tipo de relación. El siguiente grafico muestra la relación entre la variable "Type of Travel" y "satisfaction":
```{r, echo=FALSE}
library(ggplot2)
ggplot(data = sample_datos) +
  geom_histogram(mapping = aes(x = satisfaction, fill = Type.of.Travel),
                 colour = "black", binwidth = 0.5) +
  scale_fill_viridis_d() +
  facet_wrap(~ Type.of.Travel)
```
En este, podemos ver que existe una clara división entre el tipo de viaje. Podemos concluir que las personas que viajan por placer o temas personales suelen estar más insatisfechos que los que viajan por negocios. Viendo la distribución podemos ver que es una variable que realmente influye en lo que queremos predecir. 

En el siguiente histograma, queremos demostrar la relación entre la variable "Online boarding" y "satisfaction".
```{r, echo=FALSE}
log_delay_satisfecho <- log1p(delay_satisfecho)
log_delay_insatisfecho <- log1p(delay_insatisfecho)

delay_satisfecho <- sample_datos$Online.boarding[sample_datos$satisfaction == 1]
delay_insatisfecho <- sample_datos$Online.boarding[sample_datos$satisfaction == 0]

density_satisfecho <- density(delay_satisfecho, na.rm = TRUE)
density_insatisfecho <- density(delay_insatisfecho, na.rm = TRUE)

# Crear el gráfico
plot(density_satisfecho, 
     main = "Comparación de Densidades de Retrasos por Satisfacción", 
     xlab = "Online Boarding", 
     ylab = "Density", 
     col = "red", 
     lwd = 2, 
     xlim = c(0, 5))

polygon(density_satisfecho, col = rgb(1, 0, 0, 0.5), border = "red")

# Rellenar la densidad para el grupo insatisfecho
polygon(density_insatisfecho, col = rgb(0, 0, 1, 0.5), border = "blue")

# Agregar leyenda
legend("topright", 
       legend = c("Satisfechos", "Insatisfechos"), 
       fill = c(rgb(1, 0, 0, 0.5), rgb(0, 0, 1, 0.5)))
```
Vemos que las distribuciones entre ambos son diferentes por lo que entendemos a "online boarding" como una variable influyente en la satisfacción del pasajero. Tiene sentido el grafico ya que los pasajeros satisfechos puntuan con una nota alta el online boarding mientras que los pasajeros insatisfechos puntuan con una nota más baja.

# 3. Construcción de un árbol de decisión básico

Para construir el arbol, dividimos nuestro conjunto de datos en entrenamiento, con 70% de los datos, validación, con 15% de los datos, y testo, con 15% de los datos. Como nuestro sample de datos ya fue elegido al azar de un conjunto más grande, simplemente podemos dividir entre los respectivos porcentajes y nos seguiremos garantizando que sea aleatorio.

```{r}
entrenamiento <- sample_datos[1:35000,]
validacion <- sample_datos[35001:42500,]
testeo <- sample_datos[42501:50000,]
```

Con la librería rpart generamos un arbol de decision a partir de los datos de entrenamiento, utilizando los hiperparamentros por defecto.

```{r}
tree <- rpart(formula = satisfaction ~ Gender + Customer.Type + Age + Type.of.Travel + Class + Flight.Distance + Inflight.wifi.service + Departure.Arrival.time.convenient + Ease.of.Online.booking + Gate.location + Food.and.drink + Online.boarding + Seat.comfort + Inflight.entertainment + On.board.service + Leg.room.service + Baggage.handling + Checkin.service + Inflight.service + Cleanliness + Departure.Delay.in.Minutes + Arrival.Delay.in.Minutes, 
              data = entrenamiento, 
              method = "class")
tree$control
```

Dentro de los hiperparametros que toma el árbol por defecto nos encontramos que minsplit toma por defecto el valor de 20. Esto quiere decir que el numero minimo de observaciones que se necesita para dividir un nodo intermedio es de 20.

En cuanto a minbucket, este toma un valor de 7. Lo que refiere a que se necesita un minimo de 7 observaciones en cada hoja de un arbol. Esto evita que las hojas del arbol tenga muy pocas observaciones y logra que no tengamos un modelo overfitted. 

El hiperparametro cp, es el parametro de complejidad para la poda del arbol. Es de 0.01 por lo que significa que una división en el arbol debe reducir el error en al menos 1% para ser considerada util. 

Maxdepth es la maxima produnfidad permitida para la construcción del árbol y en este caso, puede tener hasta 30 niveles. Si bien cuanto más grande el árbol mejor se ajusta a los datos, si el arbol es muy profundo, se puede generar overfitting. 

Por ultimo, xval toma un valor de 10, por lo que se utilizaran 10 grupos para validación cruzada. Un mayor valor de xval te asegura una estimación más precisa pero mayor tiempo de computo.

```{r}
rpart.plot(tree)
```

En general, cada nodo cuenta con el porcentaje de datos que caen en ese nodo del total, la proporción de datos que corresponden con un dato satisfecho (satisfied = 1) y el color del nodo indica la pureza del mismo.

En el nodo raiz encontramos el 100% de los datos, de los cuales el 44% se corresponde con pasajeros satisfechos. El color del nodo no es tan intenso, dado que en este se encuentran todos los datos, los satisfechos como los insatisfecho. Como la clase predominante es insatisfecho, el nodo contiene un 0. 

El factor mas importante para determinar la satisfacción del pasajero es el online boarding. Este divide a los datos exactamente a la mitad dependiendo de si toman un valor <4. Si esto es asi, toman la rama de la izquierda, y si no, la de la derecha. 

Por la rama de la izquierda, se encuentra un nodo donde predomina la insatisfacción, al tener 0.15 de los datos satisfechos. En este podemos ver un color más puro en comparación al nodo raiz. Desde aca, se vuelve a dividir segun la variable predictoria Inflight Wifi Service. Si este es menor a 4, toma la rama de la izquierda, y si no toma la rama de la derecha.

En el caso de que tome la rama de la izquierda, vemos que los datos caen en un nodo donde predominan datos insatisfechos, con una proporcion de datos satisfechos del 0.10. Por esta razon vemos un 0 y un color muy puro. Por otro lado, vemos que la gran mayoría de los datos que caen en el nodo anterior, luego caen en este nodo al tener el 46% de los datos totales. Este nodo es divido por la misma variable predictora, con la condicion de que ahora si es mayor o igual a 1 toma la rama de la izquierda, y si no toma la rama de la derecha.

En la hoja terminal de la izquierda, vemos que si un dato cae alli es predicho como insatisfecho, dado que, en el entrenamiento, solo el 7% de los satisfechos caen alli. Podemos ver que la gran mayoría de los datos que caen en el nodo anterior estaran en este (44% del total). Por otro lado, si va hacia la hoja terminal de la derecha, este predecira como satisfecho, dado que el 100% de los datos que cayeron en este estan satisfechos. Por esta razon notamos el color más puro.

Volviendo al nodo que es divido por Inflight Wifi Service < 4, si se toma la rama de la derecha, llegamos a una hoja terminal que predecira como satisfecho. Sin embargo, este no es muy puro dado que en el entramiento solamente el 0.66 de los datos estaba satisfecho.

Volviendo al nodo raiz, si tomamos la rama de la derecha caemos en un nodo donde predomina la satisfacción, con una proporción del 0.72 de los datos  estando satisfechos. Este es dividido por si la variable Typo of Travel es igual a Personal Travel o no. Si lo es, toma la rama de la izquierda. Si no lo es, es decir el type of travel es business travel, toma la rama de la derecha.

Si vamos a la rama de la izquierda, vemos que caemos en un nodo donde predominan los datos insatisfechos dado que contiene el 23% de datos satisfechos. Este es nuevamente dividio por la variable predictora Inflight Wifi Service. Si esta toma un valor menor a 5, va hacia la hoja terminal de la izquierda donde predice como insatisfechos. En cambio, si la variable es igual a 5, predice los datos como satisfechos.

Si vamos a la rama de la derecha, caemos en una hoja terminal que predice los datos como satisfechos.

# 4. Evaluación del árbol de decisión básico

```{r}
predictions_clase <- predict(tree, newdata = testeo, type = "class")
predictions_prob <- predict(tree, newdata = testeo, type = "prob")
```

```{r}
ConfusionMatrix(y_pred = predictions_clase, y_true = testeo$satisfaction)
```
Segun la matriz de confusion obtenida, podemos ver que a simple vista que el modelo predice correctamente la gran mayoría de las veces. Notamos que la categoria con mayor observaciones es True Negative, es decir los datos insatisfechos que se predijeron correctamente como insatisfechos. Este tiene 3729 datos, un 49.72%. La segunda categoría es True Positive, es decir los datos que son satisfechos que son predichos como tal, con el 38.746%. El porcentaje restante de los datos es predicho incorrectamente, con un 7.68% que fueron predichos como insatisfechos cuando estaban satisfechos, y un 3.853% fueron predichos como satisfechos cuando estaban insatisfechos.

```{r}
Accuracy(y_pred = predictions_clase, y_true = testeo$satisfaction)
```

Como mencionamos anteriormente, el modelo predice correctamente el 88.46667% de las observaciones, la suma de los porcentajes de True-Positive y True-Negative.

```{r}
Precision(y_pred = predictions_clase, y_true = testeo$satisfaction)
```

La precision indica el porcentaje de los datos que dije que son positivos, cuantos realmente lo son. En nuestro modelo la precision es del 92.80737%, por lo que el de todos los datos positivos le acerto al 0.92

```{r}
Recall(y_pred = predictions_clase, y_true = testeo$satisfaction)
```

Recall mide de los datos que efectivamente son positivos, cuantos dice el modelo que lo son. En este caso, nuestro modelo identifico el 86.62021% de los datos positivos.

```{r}
F1_Score(y_pred = predictions_clase, y_true = testeo$satisfaction)
```

Un F1-score de 0.8960711 indica que el modelo tiene un buen balance entre precision y recall.
```{r}
AUC(y_pred = predictions_clase, y_true = testeo$satisfaction)
```
```{r}
pred <- prediction(as.numeric(predictions_clase), as.numeric(testeo$satisfaction))
roc_curve <- performance(pred, "tpr", "fpr")

plot(roc_curve, 
     main="Curva ROC", 
     col="blue", 
     lwd=2, 
     xlab="FPR", 
     ylab="TPR", 
     cex.main=1.2, 
     cex.lab=1.2)

abline(a=0, b=1, lty=2, col="red")
```

AUC-ROC se refiere al area debajo de la curva ROC. Al tener un valor de AUC de 0.8878741 podemos decir que nuestro modelo distingue bien entre clases positivas y negativas, esto se asemeja con lo que se ve en el grafico.

Analizando todas las metricas de performance, podemos concluir que nuestro modelo es muy eficiente al predecir la satisfacción de una persona, dado que se vio que tiene unabuena performance.

# 5. Optimización del modelo

Primero, definimos los valores que pueden tomar los hiperparamentros de maxdepth, minsplit y minbucket. La busqueda de los mejores hiperparametros se realizara con un grid search.

```{r}
valores_maxdepth <- seq(3, 30, by = 3)
valores_minsplit <- seq(100, 1000, by = 100)
valores_minbucket <- seq(100, 1000, by = 100)
```

Para buscar los hiperparametros, implementamos una funcion buscar_hiperparametros que toma como parametros el conjunto de entrenamiento y el de validacion, al igua que los valores que podran tomar los hiperparametros mencionados anteriormente.

```{r}
buscar_hiperparametros <- function(entrenamiento, validacion, valores_maxdepth, valores_minsplit, valores_minbucket){
  valores_auc <- c()
  best_auc <- 0
  best_params <- c()
  for (i in 1:length(valores_maxdepth)){
    for (j in 1:length(valores_minsplit)){
      for (l in 1:length(valores_minbucket)){
        tree2 <- rpart(formula = satisfaction ~ Gender + Customer.Type + Age + Type.of.Travel + Class + Flight.Distance + Inflight.wifi.service + Departure.Arrival.time.convenient + Ease.of.Online.booking + Gate.location + Food.and.drink + Online.boarding + Seat.comfort + Inflight.entertainment + On.board.service + Leg.room.service + Baggage.handling + Checkin.service + Inflight.service + Cleanliness + Departure.Delay.in.Minutes + Arrival.Delay.in.Minutes, 
                data = entrenamiento, 
                method = "class",
                control = rpart.control(maxdepth = valores_maxdepth[i], minsplit = valores_minsplit[j], minbucket = valores_minbucket[l], cp = 0, xval = 0))
      
        predicciones <- predict(tree2, newdata = validacion, type = "class")

        auc <- AUC(y_pred = predicciones, y_true = validacion$satisfaction)
        valores_auc <- c(valores_auc, auc)
      
        if (auc > best_auc){
          best_auc <- auc
          best_params <- c(valores_maxdepth[i], valores_minsplit[j], valores_minbucket[l])
        }
      }
    }
  }
  return (list(valores_auc = valores_auc, best_auc = best_auc, best_params = best_params))
}
```

Para implementar el grid search, hicimos un triple for anidado para probar todos los valores de los hiperparametros contra todos. En cada combinación, se modela un arbol, se genera predicciones para el conjunto de validación y se calcula el AUC. Si este valor es mayor al mejor AUC guardado, se guarda este nuevo AUC al igual que los valores de los parametros que hicieron que se llegue a este valor de area debajo de la curva. Una vez que se recorren todos los valores que se puede tomar, se devuelven los mejores.

```{r}
best <- buscar_hiperparametros(entrenamiento = entrenamiento, validacion = validacion, valores_maxdepth = valores_maxdepth, valores_minsplit = valores_minsplit, valores_minbucket = valores_minbucket)
best$valores_auc
best$best_auc
best$best_params
```

Una vez que tenemos los valores que maximizan el AUC en validación, modelamos el arbol correspondiente a estos, generamos las predicciones para el conjunto de test y calculamos el AUC para los datos nuevos.

```{r}
best_tree <- rpart(formula = satisfaction ~ Gender + Customer.Type + Age + Type.of.Travel + Class + Flight.Distance + Inflight.wifi.service + Departure.Arrival.time.convenient + Ease.of.Online.booking + Gate.location + Food.and.drink + Online.boarding + Seat.comfort + Inflight.entertainment + On.board.service + Leg.room.service + Baggage.handling + Checkin.service + Inflight.service + Cleanliness + Departure.Delay.in.Minutes + Arrival.Delay.in.Minutes, 
              data = entrenamiento, 
              method = "class",
              control = rpart.control(maxdepth = best$best_params[1], minsplit = best$best_params[2], minbucket = best$best_params[3], cp = 0, xval = 0))
best_predicciones <- predict(best_tree, newdata = testeo, type = "class")
AUC(y_pred = best_predicciones, y_true = testeo$satisfaction)
```

En el arbol basico (punto #3) el arbol tenia un AUC de 0.8878741 con los hiperparamentros por defecto. Este arbol optimizado toma un valor de AUC de 0.9265255. Este ultimo tiene una mejor performance dado que se eligio (dentro de un rango de valores posibles) los valores que mejores predecian la satifacción para el conjunto de validación. Notamos que el alto valor en AUC en validación no se debe a overfitting si no que se mejora la predicción del modelo, dado que el AUC en testeo es muy similar.

# 6. Interpretación de resultados
```{r}
rpart.plot(best_tree)
```

A simple vista, podemos ver que la variable predictora en el nodo raiz es la misma en ambos arboles, Online boarding < 4, y los valores encontrados en el nodo coinciden. Siguiendo por la rama de la izquierda, podemos ver que el siguiente corte es el mismo, se utiliza Inflight Wifi Service < 4, y se tienen los mismos valores en los nodos. Por la rama izquierda de este, se tiene el mismo corte de Inflight Wifi Service >= 1. Luego de este, empiezan a diferir. Vemos que si se utiliza la rama derecha luego del segundo corte, este cambia dado que aparecen nuevos cortes dados por otras variables predictoras.

Hacia la derecha del nodo raiz, el nodo tiene los mismos valores en ambos arboles, pero en el arbol optimizado la variable predictora que hace el corte cambia, pasa de ser Type of Travel = Personal Travel a Inflight entretaiment < 4, y los demas cortes son distintos y en mayor cantidad.

```{r}
importancia_variables_best <- best_tree$variable.importance

importancia_variables_best
```

Podemos ver que las variables predictoras más importantes son Online Boarding, Inflight Wifi Service y Seat Comfort. Esto se correlaciona con el grafico dado que son los primeros cortes que figuran en el arbol y son los que más cortes realizan.

```{r}
importancia_variables_basico <- tree$variable.importance

importancia_variables_basico
```

Si lo comparamos con el arbol basico, notamos primero que todos aumentaron su valor en el optimizado y que aparecen las mismas categorías en ambas solo que en el optimizado se incluye Check-in service. Por otro lado, podemos ver que el orden de importancia cambia. On board service y Leg room service suben dos posiciones y  Baggage handling baja dos posiciones. Con esto, podemos ver que la importancia de las variables va a cambiar dependiendo de los hiperparametros que tomen los modelos.

**7. Análisis del impacto de los valores faltantes**

Para generar datasets con datos faltantes, creamos una nueva función reemplazar_na, a la cual le pasamos por parámetros los datos y el porcentaje de NA que queríamos tener. La idea de esta función era recorrer todas las columnas del conjunto de datos, excluyendo a la columna correspondien te a la variable a predecir (Satisfaction). Por cada columna, calculamos la cantidad de NA que ya tiene, la cantidad de NA que se quieren tener y la diferencia para saber cuantos más hay que agregar. Si esta diferencia es mayor a 0, entonces agregamos los NA faltantes a la columna de manera aleatoria.

```{r}
reemplazar_na <- function(data, porcentaje_na) {
  total_filas <- nrow(data)
  total_columnas <- ncol(data)  # Número total de columnas

  for (i in 1:(total_columnas - 1)) {  # Iterar hasta la anteúltima columna
    col <- colnames(data)[i]
    
    # Contar el número actual de NA en la columna
    na_existentes <- sum(is.na(data[[col]]))
    
    # Calcular cuántos NA totales debería haber para alcanzar el porcentaje deseado
    num_na_deseado <- round(porcentaje_na * total_filas)
    
    nuevos_na <- num_na_deseado - na_existentes
    
    # Solo agregar nuevos NA si el número necesario es positivo
    if (nuevos_na > 0) {
      na_indices <- sample(which(!is.na(data[[col]])), size = nuevos_na)
      data[na_indices, col] <- NA
    }
  }
  return(data)
}
```

Utilizamos esta función para generar datasets con datos con el 20%, 50% y 75% de datos faltantes.

```{r}
entrenamiento_na_20 <- reemplazar_na(entrenamiento, 0.20)
validacion_na_20 <- reemplazar_na(validacion, 0.20)
testeo_na_20 <- reemplazar_na(testeo, 0.01)

entrenamiento_na_50 <- reemplazar_na(entrenamiento, 0.50)
validacion_na_50 <- reemplazar_na(validacion, 0.50)
testeo_na_50 <- reemplazar_na(testeo, 0.50)

entrenamiento_na_75 <- reemplazar_na(entrenamiento, 0.75)
validacion_na_75 <- reemplazar_na(validacion, 0.75)
testeo_na_75 <- reemplazar_na(testeo, 0.75)
```

Para cada uno de los datasets, buscamos los hiperparámetros a través de la función creada anteriormente, para encontrar los valores de los hiperparámetros que lo optimizan.

```{r}
best_na_20 <- buscar_hiperparametros(entrenamiento = entrenamiento_na_20, validacion = validacion_na_20, valores_maxdepth = valores_maxdepth, valores_minsplit = valores_minsplit, valores_minbucket = valores_minbucket)

best_na_20$valores_auc
best_na_20$best_auc
best_na_20$best_params
```
```{r}
best_tree_na_20 <- rpart(formula = satisfaction ~ ., 
              data = entrenamiento_na_20, 
              method = "class",
              control = rpart.control(maxdepth = best_na_20$best_params[1], minsplit = best_na_20$best_params[2], minbucket = best_na_20$best_params[3], cp = 0, xval = 0))
best_predicciones <- predict(best_tree_na_20, newdata = testeo_na_20, type = "class")
auc_20 <- AUC(y_pred = best_predicciones, y_true = testeo_na_20$satisfaction)
auc_faltantes <- c(auc_20)
```
```{r}
rpart.plot(best_tree_na_20)
```
```{r}
best_na_50 <- buscar_hiperparametros(entrenamiento = entrenamiento_na_50, validacion = validacion_na_50, valores_maxdepth = valores_maxdepth, valores_minsplit = valores_minsplit, valores_minbucket = valores_minbucket)


best_na_50$valores_auc
best_na_50$best_auc
best_na_50$best_params
```
```{r}
best_tree_na_50 <- rpart(formula = satisfaction ~ ., 
              data = entrenamiento_na_50, 
              method = "class",
              control = rpart.control(maxdepth = best_na_50$best_params[1], minsplit = best_na_50$best_params[2], minbucket = best_na_50$best_params[3], cp = 0, xval = 0))
best_predicciones <- predict(best_tree_na_50, newdata = testeo_na_50, type = "class")
auc_50 <- AUC(y_pred = best_predicciones, y_true = testeo_na_50$satisfaction)
auc_faltantes <- c(auc_faltantes, auc_50)
```
```{r}
rpart.plot(best_tree_na_50)
```
```{r}
best_na_75 <- buscar_hiperparametros(entrenamiento = entrenamiento_na_75, validacion = validacion_na_75, valores_maxdepth = valores_maxdepth, valores_minsplit = valores_minsplit, valores_minbucket = valores_minbucket)

best_na_75$valores_auc
best_na_75$best_auc
best_na_75$best_params
```
```{r}
best_tree_na_75 <- rpart(formula = satisfaction ~ ., 
              data = entrenamiento_na_75, 
              method = "class",
              control = rpart.control(maxdepth = best_na_75$best_params[1], minsplit = best_na_75$best_params[2], minbucket = best_na_75$best_params[3], cp = 0, xval = 0))
best_predicciones <- predict(best_tree_na_75, newdata = testeo_na_75, type = "class")
auc_75 <- AUC(y_pred = best_predicciones, y_true = testeo_na_75$satisfaction)
auc_faltantes <- c(auc_faltantes, auc_75)
```
```{r}
rpart.plot(best_tree_na_75)
```

Pudimos observar que existe una relación inversa entre el porcentaje de datos faltantes y el AUC: mientras más datos faltantes tiene el conjunto, menor es el AUC.

```{r}
df_auc <- data.frame(
  porcentajes <- c(20, 50, 75),
  auc_faltantes
)

ggplot(df_auc, aes(x = porcentajes, y = auc_faltantes)) +
  geom_line(color = "blue") +  # Línea que conecta los puntos
  geom_point(size = 3, color = "red") +  # Puntos de AUC
  labs(title = "Relación entre AUC y Porcentaje de Datos Faltantes",
       x = "Porcentaje de Datos Faltantes",
       y = "AUC") +
  theme_minimal()
```

[^1]: https://www.kaggle.com/datasets/teejmahal20/airline-passenger-satisfaction