---
title: "TP1"
author: "Catalina Dolhare, Camila Cauzzo, Renata Squillari"
date: "`r Sys.Date()`"
output:
  word_document: default
  pdf_document: default
---

# 1. Introducción al problema

El siguiente conjunto de datos presenta información acerca de una encuesta de satisfacción a pasageros de una cierta aerolinea. Obtuvimos este dataset de Kaggle[^1], el cual cuenta con un conjunto de train con 104000 datos, representando el 80% del data set, y un conjunto de test con 26000 datos, representando el 20% del data set. Este data set cuenta con 23 variables, como "Type of travel", "Class", "Flight distance", "Departure Delay in Minutes", "Arrival Delay in Minutes". Principalmente, cuenta con "Satisfaction", variable categorica que puede tomar dos opciones: "Satisfaction" o "neutral or dissatisfaction".Con toda esta información, intentaremos predecir la satisfacción de un pasajero dado las respuesta a las variables.

Utilizamos este conjunto de datos dado que contiene diversas variables predictoras y no tiene un gran numero de datos faltantes (solo se encuentran datos faltas en una de las variables), por lo que podremos predecir un buen modelo.

Para el siguiente trabajo se necesitan importar las siguientes librerias:
```{r}
#install.packages("ggplot2")
#install.packages("corrplot")
#install.packages("MLmetrics")

library(ggplot2)
library(corrplot)
library(rpart)
library(rpart.plot)
library(MLmetrics)
library(ROCR)
```


# 2. Preparación de los datos

Como nuestro data set venia con dos conjuntos de datos que sumaban un total de aproximadamente 130.000 observaciones, decidimos juntar todos los datos y elegir aleatoriamente 50.000 datos. Para hacer esto y que sea repicable los datos que se eligan, utilizamos una semilla.

```{r}
datos_train <- read.csv("train.csv")
datos_test <- read.csv("test.csv")
```

```{r}
datos<-rbind(datos_train, datos_test)
```

```{r}
set.seed(123)
sample_datos <- datos[sample(nrow(datos), 50000),]
nrow(sample_datos)
```

Para la variable satisfaction, que es lo que queremos predecir, originalmente era categorica, pero decidimos transformarla en numerica donde satisfied = 1 y neutral o disatisfied = 0. Esto lo hicimos para poder analizar graficamente las variables predictoras contra satisfaction, dado que no podiamos realizarlo si esta era categorica.

```{r}
sample_datos$satisfaction <- as.numeric(as.factor(sample_datos$satisfaction)) - 1
```

Para poder ver las estadisticas descriptivas de las varibales, realizamos un summary de los datos. Este nos provee el minimo, los quartiles, la media, la mediana y el maximo de las variables numericas.

```{r}
summary(sample_datos)
```
A simple vista, vemos en la variable de satisfaction una mediana de 0 y una media 0.4338. Esto nos indica que hay mas pasajeros insatisfechos (0) que satisfechos (1).

Por otro lado, notamos que las variables que tiene una escala de 0 a 5 tiene mediana y media en aproximadamente 3, esto significa que en su mayoria las personas se encuentran indiferente dentro de cada categoría.

Para ver si las otras variables predictoras influyen en satisfacion hicimos una matriz de correlacion. Sabemos que correlacion no implica causalidad, no obstante, es bueno para visualizar y descartar variables que no influyen directamente en la satisfación de los pasajeros.

```{r, echo=FALSE}
numeric_data <- sample_datos[, sapply(sample_datos, is.numeric)]
cor_matrix <- cor(numeric_data)
corrplot(cor_matrix, method = "color", 
         tl.col = "black", tl.srt = 45, tl.cex = 0.5,  # Ajustes de etiquetas
         cl.ratio = 0.2,  # Ajustar el tamaño de las celdas
         addgrid.col = "black", # Añadir color a las líneas de la cuadrícula
         addCoef.col = "black",
         number.cex = 0.3)  
```

En esta matriz nos importa ver los valores que hay en la fila/columna de satisfaction para ver como las variables predictoras se relacionan con la variable que queremos predecir. Sin embargo, notamos que existen correlaciones entre variables predictoras.

Se puede ver que hay algunas variables que no tienen correlación con la satisfación, estas son: "Departure Arrival time convenient", "Gate of location", "Departure Delay in minutes". Por otro lado, notamos que hay variables que tienen una correlación alta con la satisfacción, como lo es Online Boarding o Inflight entretainment.

Para analizar si realmente estas variables con mucha correlación realmente influyen en la satisfacción del pasajero, graficamos un histograma del Online Boarding separando entre los pasajeros que estaban satisfechos o insatisfechos.

```{r, echo=FALSE}
delay_satisfecho <- sample_datos$Online.boarding[sample_datos$satisfaction == 1]
delay_insatisfecho <- sample_datos$Online.boarding[sample_datos$satisfaction == 0]

density_satisfecho <- density(delay_satisfecho, na.rm = TRUE)
density_insatisfecho <- density(delay_insatisfecho, na.rm = TRUE)

# Crear el gráfico
plot(density_satisfecho, 
     main = "Comparación de Online Boarding por Satisfacción", 
     xlab = "Online Boarding", 
     ylab = "Density", 
     col = "red", 
     lwd = 2, 
     xlim = c(0, 5))

polygon(density_satisfecho, col = rgb(1, 0, 0, 0.5), border = "red")

# Rellenar la densidad para el grupo insatisfecho
polygon(density_insatisfecho, col = rgb(0, 0, 1, 0.5), border = "blue")

# Agregar leyenda
legend("topright", 
       legend = c("Satisfechos", "Insatisfechos"), 
       fill = c(rgb(1, 0, 0, 0.5), rgb(0, 0, 1, 0.5)))
```

Podemos ver que las densidades de pasajeros satisfechos e insatisfechos estan separadas. Los insatisfechos tuvieron una puntuación en Online Boarding más baja que los satisfechos. Viendo estas distribuciones, podemos asumir que esta variable tendra importancia a la hora de generar un modelo.

Por otro lado, como la matriz de confusión se calcula solo sobre las variables numericas, no podemos descartar que las variables categoricas influyan sobre la satisfacción. 

Para analizar una de ellas, Type of Travel, realizamos dos histogramas, dividios por si era un Personal Travel o un Business Travel.

```{r, echo=FALSE}
library(ggplot2)
ggplot(data = sample_datos) +
  geom_histogram(mapping = aes(x = satisfaction, fill = Type.of.Travel),
                 colour = "black", binwidth = 0.5) +
  scale_fill_viridis_d() +
  facet_wrap(~ Type.of.Travel)
```

En este, podemos ver que existe una clara división entre el tipo de viaje, dado que en Personal Travel existen una diferencia muy clara donde predomina la insatisfacción, y en Business Travel, no hay mucha diferencia, pero predomina la satisfacción. De esto, podemos concluir que las personas que viajan por placer o temas personales suelen estar más insatisfechos que los que viajan por negocios. 

Por otro lado, volviendo a las variables que no presentaron correlación con la satisfacción, graficamos la densidad de Departure Arrival time convenient separado por satisfacción para ver si realmente no influyen en la satisfacción.

```{r, echo=FALSE}
delay_satisfecho <- sample_datos$Departure.Arrival.time.convenient[sample_datos$satisfaction == 1]
delay_insatisfecho <- sample_datos$Departure.Arrival.time.convenient[sample_datos$satisfaction == 0]

density_satisfecho <- density(delay_satisfecho, na.rm = TRUE)
density_insatisfecho <- density(delay_insatisfecho, na.rm = TRUE)

# Crear el gráfico
plot(density_satisfecho, 
     main = "Comparación de Departure Arrival time convenient", 
     xlab = "Departure Arrival Time Convenient", 
     ylab = "Density", 
     col = "red", 
     lwd = 2, 
     xlim = c(0, 5))

polygon(density_satisfecho, col = rgb(1, 0, 0, 0.5), border = "red")

# Rellenar la densidad para el grupo insatisfecho
polygon(density_insatisfecho, col = rgb(0, 0, 1, 0.5), border = "blue")

# Agregar leyenda
legend("topright", 
       legend = c("Satisfechos", "Insatisfechos"), 
       fill = c(rgb(1, 0, 0, 0.5), rgb(0, 0, 1, 0.5)))
```

En este caso, podemos ver que las dos densidades en todo momento estan muy pegadas y no se nota una clara diferencia entre ambas. En función de esto, podemos decir que esta variable predictora no sera relevante para la predicción de satisfacción de un pasajero, y probablemente no se utilice como corte en un arbol de decisión.

# 3. Construcción de un árbol de decisión básico

Para construir el arbol, dividimos nuestro conjunto de datos en entrenamiento, con 70% de los datos, validación, con 15% de los datos, y testo, con 15% de los datos. Como nuestro sample de datos ya fue elegido al azar de un conjunto más grande, simplemente podemos dividir entre los respectivos porcentajes y nos seguiremos garantizando que sea aleatorio.

```{r}
entrenamiento <- sample_datos[1:35000,]
validacion <- sample_datos[35001:42500,]
testeo <- sample_datos[42501:50000,]
```

Con la librería rpart generamos un arbol de decision a partir de los datos de entrenamiento, utilizando los hiperparamentros por defecto.

```{r}
tree <- rpart(formula = satisfaction ~ Gender + Customer.Type + Age + Type.of.Travel + Class + Flight.Distance + Inflight.wifi.service + Departure.Arrival.time.convenient + Ease.of.Online.booking + Gate.location + Food.and.drink + Online.boarding + Seat.comfort + Inflight.entertainment + On.board.service + Leg.room.service + Baggage.handling + Checkin.service + Inflight.service + Cleanliness + Departure.Delay.in.Minutes + Arrival.Delay.in.Minutes, 
              data = entrenamiento, 
              method = "class")
tree$control
```

Dentro de los hiperparametros que toma el árbol por defecto nos encontramos que minsplit toma por defecto el valor de 20. Esto quiere decir que el numero minimo de observaciones que se necesita para dividir un nodo intermedio es de 20.

En cuanto a minbucket, este toma un valor de 7. Lo que refiere a que se necesita un minimo de 7 observaciones en cada hoja de un arbol. Esto evita que las hojas del arbol tenga muy pocas observaciones y logra que no tengamos un modelo overfitted. 

El hiperparametro cp, es el parametro de complejidad para la poda del arbol. Es de 0.01 por lo que significa que una división en el arbol debe reducir el error en al menos 1% para ser considerada util. 

Maxdepth es la maxima produnfidad permitida para la construcción del árbol y en este caso, puede tener hasta 30 niveles. Si bien cuanto más grande el árbol mejor se ajusta a los datos, si el arbol es muy profundo, se puede generar overfitting. 

Por ultimo, xval toma un valor de 10, por lo que se utilizaran 10 grupos para validación cruzada. Un mayor valor de xval te asegura una estimación más precisa pero mayor tiempo de computo.

```{r}
rpart.plot(tree)
```

En general, cada nodo cuenta con el porcentaje de datos que caen en ese nodo del total, la proporción de datos que corresponden con un dato satisfecho (satisfied = 1) y el color del nodo indica la pureza del mismo.

En el nodo raiz encontramos el 100% de los datos, de los cuales el 44% se corresponde con pasajeros satisfechos. El color del nodo no es tan intenso, dado que en este se encuentran todos los datos, los satisfechos como los insatisfecho. Como la clase predominante es insatisfecho, el nodo contiene un 0. 

El factor mas importante para determinar la satisfacción del pasajero es el online boarding. Este divide a los datos exactamente a la mitad dependiendo de si toman un valor <4. Si esto es asi, toman la rama de la izquierda, y si no, la de la derecha. 

Por la rama de la izquierda, se encuentra un nodo donde predomina la insatisfacción, al tener 0.15 de los datos satisfechos. En este podemos ver un color más puro en comparación al nodo raiz. Desde aca, se vuelve a dividir segun la variable predictoria Inflight Wifi Service. Si este es menor a 4, toma la rama de la izquierda, y si no toma la rama de la derecha.

En el caso de que tome la rama de la izquierda, vemos que los datos caen en un nodo donde predominan datos insatisfechos, con una proporcion de datos satisfechos del 0.10. Por esta razon vemos un 0 y un color muy puro. Por otro lado, vemos que la gran mayoría de los datos que caen en el nodo anterior, luego caen en este nodo al tener el 46% de los datos totales. Este nodo es divido por la misma variable predictora, con la condicion de que ahora si es mayor o igual a 1 toma la rama de la izquierda, y si no toma la rama de la derecha.

En la hoja terminal de la izquierda, vemos que si un dato cae alli es predicho como insatisfecho, dado que, en el entrenamiento, solo el 7% de los satisfechos caen alli. Podemos ver que la gran mayoría de los datos que caen en el nodo anterior estaran en este (44% del total). Por otro lado, si va hacia la hoja terminal de la derecha, este predecira como satisfecho, dado que el 100% de los datos que cayeron en este estan satisfechos. Por esta razon notamos el color más puro.

Volviendo al nodo que es divido por Inflight Wifi Service < 4, si se toma la rama de la derecha, llegamos a una hoja terminal que predecira como satisfecho. Sin embargo, este no es muy puro dado que en el entramiento solamente el 0.66 de los datos estaba satisfecho.

Volviendo al nodo raiz, si tomamos la rama de la derecha caemos en un nodo donde predomina la satisfacción, con una proporción del 0.72 de los datos  estando satisfechos. Este es dividido por si la variable Typo of Travel es igual a Personal Travel o no. Si lo es, toma la rama de la izquierda. Si no lo es, es decir el type of travel es business travel, toma la rama de la derecha.

Si vamos a la rama de la izquierda, vemos que caemos en un nodo donde predominan los datos insatisfechos dado que contiene el 23% de datos satisfechos. Este es nuevamente dividio por la variable predictora Inflight Wifi Service. Si esta toma un valor menor a 5, va hacia la hoja terminal de la izquierda donde predice como insatisfechos. En cambio, si la variable es igual a 5, predice los datos como satisfechos.

Si vamos a la rama de la derecha, caemos en una hoja terminal que predice los datos como satisfechos.

# 4. Evaluación del árbol de decisión básico

```{r}
predictions_clase <- predict(tree, newdata = testeo, type = "class")
predictions_prob <- predict(tree, newdata = testeo, type = "prob")
```

```{r}
ConfusionMatrix(y_pred = predictions_clase, y_true = testeo$satisfaction)
```

Segun la matriz de confusion obtenida, podemos ver que a simple vista que el modelo predice correctamente la gran mayoría de las veces. Notamos que la categoria con mayor observaciones es True Negative, es decir los datos insatisfechos que se predijeron correctamente como insatisfechos. Este tiene 3729 datos, un 49.72%. La segunda categoría es True Positive, es decir los datos que son satisfechos que son predichos como tal, con el 38.746%. El porcentaje restante de los datos es predicho incorrectamente, con un 7.68% que fueron predichos como insatisfechos cuando estaban satisfechos, y un 3.853% fueron predichos como satisfechos cuando estaban insatisfechos.

```{r}
Accuracy(y_pred = predictions_clase, y_true = testeo$satisfaction)
```

Como mencionamos anteriormente, el modelo predice correctamente el 88.46667% de las observaciones, la suma de los porcentajes de True-Positive y True-Negative.

```{r}
Precision(y_pred = predictions_clase, y_true = testeo$satisfaction)
```

La precision indica el porcentaje de los datos que dije que son positivos, cuantos realmente lo son. En nuestro modelo la precision es del 92.80737%, por lo que el de todos los datos positivos le acerto al 0.92

```{r}
Recall(y_pred = predictions_clase, y_true = testeo$satisfaction)
```

Recall mide de los datos que efectivamente son positivos, cuantos dice el modelo que lo son. En este caso, nuestro modelo identifico el 86.62021% de los datos positivos.

```{r}
F1_Score(y_pred = predictions_clase, y_true = testeo$satisfaction)
```

Un F1-score de 0.8960711 indica que el modelo tiene un buen balance entre precision y recall.

```{r}
AUC(y_pred = predictions_clase, y_true = testeo$satisfaction)
```

```{r}
pred <- prediction(as.numeric(predictions_clase), as.numeric(testeo$satisfaction))
roc_curve <- performance(pred, "tpr", "fpr")

plot(roc_curve, 
     main="Curva ROC", 
     col="blue", 
     lwd=2, 
     xlab="FPR", 
     ylab="TPR", 
     cex.main=1.2, 
     cex.lab=1.2)

abline(a=0, b=1, lty=2, col="red")
```

AUC-ROC se refiere al area debajo de la curva ROC. Al tener un valor de AUC de 0.8878741 podemos decir que nuestro modelo distingue bien entre clases positivas y negativas, esto se asemeja con lo que se ve en el grafico.

Analizando todas las metricas de performance, podemos concluir que nuestro modelo es muy eficiente al predecir la satisfacción de una persona, dado que se vio que tiene unabuena performance.

# 5. Optimización del modelo

Primero, definimos los valores que pueden tomar los hiperparamentros de maxdepth, minsplit y minbucket. La busqueda de los mejores hiperparametros se realizara con un grid search.

```{r}
valores_maxdepth <- seq(3, 30, by = 3)
valores_minsplit <- seq(100, 1000, by = 100)
valores_minbucket <- seq(100, 1000, by = 100)
```

Para buscar los hiperparametros, implementamos una funcion buscar_hiperparametros que toma como parametros el conjunto de entrenamiento y el de validacion, al igua que los valores que podran tomar los hiperparametros mencionados anteriormente.

```{r}
buscar_hiperparametros <- function(entrenamiento, validacion, valores_maxdepth, valores_minsplit, valores_minbucket){
  valores_auc <- c()
  best_auc <- 0
  best_params <- c()
  for (i in 1:length(valores_maxdepth)){
    for (j in 1:length(valores_minsplit)){
      for (l in 1:length(valores_minbucket)){
        tree2 <- rpart(formula = satisfaction ~ Gender + Customer.Type + Age + Type.of.Travel + Class + Flight.Distance + Inflight.wifi.service + Departure.Arrival.time.convenient + Ease.of.Online.booking + Gate.location + Food.and.drink + Online.boarding + Seat.comfort + Inflight.entertainment + On.board.service + Leg.room.service + Baggage.handling + Checkin.service + Inflight.service + Cleanliness + Departure.Delay.in.Minutes + Arrival.Delay.in.Minutes, 
                data = entrenamiento, 
                method = "class",
                control = rpart.control(maxdepth = valores_maxdepth[i], minsplit = valores_minsplit[j], minbucket = valores_minbucket[l], cp = 0, xval = 0))
      
        predicciones <- predict(tree2, newdata = validacion, type = "class")

        auc <- AUC(y_pred = predicciones, y_true = validacion$satisfaction)
        valores_auc <- c(valores_auc, auc)
      
        if (auc > best_auc){
          best_auc <- auc
          best_params <- c(valores_maxdepth[i], valores_minsplit[j], valores_minbucket[l])
        }
      }
    }
  }
  return (list(valores_auc = valores_auc, best_auc = best_auc, best_params = best_params))
}
```

Para implementar el grid search, hicimos un triple for anidado para probar todos los valores de los hiperparametros contra todos. En cada combinación, se modela un arbol, se genera predicciones para el conjunto de validación y se calcula el AUC. Si este valor es mayor al mejor AUC guardado, se guarda este nuevo AUC al igual que los valores de los parametros que hicieron que se llegue a este valor de area debajo de la curva. Una vez que se recorren todos los valores que se puede tomar, se devuelven los mejores.

```{r}
best <- buscar_hiperparametros(entrenamiento = entrenamiento, validacion = validacion, valores_maxdepth = valores_maxdepth, valores_minsplit = valores_minsplit, valores_minbucket = valores_minbucket)

best$best_auc
best$best_params
```

```{r}
valores_auc_depth <- c()

for (i in 1:length(valores_maxdepth)){
  tree_depth <- rpart(formula = satisfaction ~ Gender + Customer.Type + Age + Type.of.Travel + Class + Flight.Distance + Inflight.wifi.service + Departure.Arrival.time.convenient + Ease.of.Online.booking + Gate.location + Food.and.drink + Online.boarding + Seat.comfort + Inflight.entertainment + On.board.service + Leg.room.service + Baggage.handling + Checkin.service + Inflight.service + Cleanliness + Departure.Delay.in.Minutes + Arrival.Delay.in.Minutes, 
                data = entrenamiento, 
                method = "class",
                control = rpart.control(maxdepth = valores_maxdepth[i], minsplit = best$best_params[2], minbucket = best$best_params[3], cp = 0, xval = 0))
      
  predicciones_depth <- predict(tree_depth, newdata = validacion, type = "class")

  auc_depth <- AUC(y_pred = predicciones_depth, y_true = validacion$satisfaction)
  valores_auc_depth <- c(valores_auc_depth, auc_depth)
}

valores_auc_depth
```

```{r}
resultados <- data.frame(
  maxdepth = seq(3, 30, by = 3),
  auc = valores_auc_depth
)

ggplot(resultados, aes(x = maxdepth, y = auc)) +
  geom_line(color = "green") +
  geom_point(color = "pink") +
  labs(title = "AUC-ROC en función de la profundidad máxima",
       x = "maxdepth",
       y = "AUC-ROC") +
  theme_minimal()

```

Podemos ver que a medida que el maxdepth aumenta, hay mejor performance. Sin embargo, esta relación no es lineal, a partir de un maxdepth de 15 aproximadamente el valor de AUC es asintotico a 0.93, alcanzando un maximo en la peformance del modelo. A mayor profundida, pueden haber más diviciones en el arbol y se puede ajustar mejor a los datos.

```{r}
valores_auc_split <- c()

for (i in 1:length(valores_minsplit)){
  tree_split <- rpart(formula = satisfaction ~ Gender + Customer.Type + Age + Type.of.Travel + Class + Flight.Distance + Inflight.wifi.service + Departure.Arrival.time.convenient + Ease.of.Online.booking + Gate.location + Food.and.drink + Online.boarding + Seat.comfort + Inflight.entertainment + On.board.service + Leg.room.service + Baggage.handling + Checkin.service + Inflight.service + Cleanliness + Departure.Delay.in.Minutes + Arrival.Delay.in.Minutes, 
                data = entrenamiento, 
                method = "class",
                control = rpart.control(maxdepth = best$best_params[1], minsplit = valores_minsplit[i], minbucket = best$best_params[3], cp = 0, xval = 0))
      
  predicciones_split <- predict(tree_split, newdata = validacion, type = "class")

  auc_split <- AUC(y_pred = predicciones_split, y_true = validacion$satisfaction)
  valores_auc_split <- c(valores_auc_split, auc_split)
}

valores_auc_split
```

```{r}
resultados_split <- data.frame(
  minsplit = seq(100, 1000, by = 100),
  auc = valores_auc_split
)

ggplot(resultados_split, aes(x = minsplit, y = auc)) +
  geom_line(color = "green") +
  geom_point(color = "pink") +
  labs(title = "AUC-ROC en función de minsplit",
       x = "minsplit",
       y = "AUC-ROC") +
  theme_minimal()

```

Podemos ver que existe un a relación inversamente proporcional entre el minsplit y el AUC, es decir, a medida que se aumenta el minsplit, la performance disminuye. Esto tiene sentido, dado que cada vez se necesitan más observaciones para dividir un nodo, por lo que se ajusta cada vez peor a los datos.

```{r}
valores_auc_bucket <- c()

for (i in 1:length(valores_minbucket)){
  tree_bucket <- rpart(formula = satisfaction ~ Gender + Customer.Type + Age + Type.of.Travel + Class + Flight.Distance + Inflight.wifi.service + Departure.Arrival.time.convenient + Ease.of.Online.booking + Gate.location + Food.and.drink + Online.boarding + Seat.comfort + Inflight.entertainment + On.board.service + Leg.room.service + Baggage.handling + Checkin.service + Inflight.service + Cleanliness + Departure.Delay.in.Minutes + Arrival.Delay.in.Minutes, 
                data = entrenamiento, 
                method = "class",
                control = rpart.control(maxdepth = best$best_params[1], minsplit = best$best_params[2], minbucket = valores_minbucket[i], cp = 0, xval = 0))
      
  predicciones_bucket <- predict(tree_bucket, newdata = validacion, type = "class")

  auc_bucket <- AUC(y_pred = predicciones_bucket, y_true = validacion$satisfaction)
  valores_auc_bucket <- c(valores_auc_bucket, auc_bucket)
}

valores_auc_bucket
```

```{r}
resultados_bucket <- data.frame(
  minbucket = seq(100, 1000, by = 100),
  auc = valores_auc_bucket
)

ggplot(resultados_bucket, aes(x = minbucket, y = auc)) +
  geom_line(color = "green") +
  geom_point(color = "pink") +
  labs(title = "AUC-ROC en función de minbucket",
       x = "minbucket",
       y = "AUC-ROC") +
  theme_minimal()

```

Nuevamente podemos ver que existe un a relación inversamente proporcional entre el minbucket y el AUC, es decir, a medida que se aumenta el minbucket, la performance disminuye. Esto tiene sentido, dado que cada vez se necesitan más observaciones para tener una hoja terminal, por lo que se ajusta cada vez peor a los datos.

Una vez que tenemos los valores que maximizan el AUC en validación, modelamos el arbol correspondiente a estos, generamos las predicciones para el conjunto de test y calculamos el AUC para los datos nuevos.

```{r}
best_tree <- rpart(formula = satisfaction ~ Gender + Customer.Type + Age + Type.of.Travel + Class + Flight.Distance + Inflight.wifi.service + Departure.Arrival.time.convenient + Ease.of.Online.booking + Gate.location + Food.and.drink + Online.boarding + Seat.comfort + Inflight.entertainment + On.board.service + Leg.room.service + Baggage.handling + Checkin.service + Inflight.service + Cleanliness + Departure.Delay.in.Minutes + Arrival.Delay.in.Minutes, 
              data = entrenamiento, 
              method = "class",
              control = rpart.control(maxdepth = best$best_params[1], minsplit = best$best_params[2], minbucket = best$best_params[3], cp = 0, xval = 0))
best_predicciones <- predict(best_tree, newdata = testeo, type = "class")
AUC(y_pred = best_predicciones, y_true = testeo$satisfaction)
```

En el arbol basico (punto #3) el arbol tenia un AUC de 0.8878741 con los hiperparamentros por defecto. Este arbol optimizado toma un valor de AUC de 0.9265255. Este ultimo tiene una mejor performance dado que se eligio (dentro de un rango de valores posibles) los valores que mejores predecian la satifacción para el conjunto de validación. Notamos que el alto valor en AUC en validación no se debe a overfitting si no que se mejora la predicción del modelo, dado que el AUC en testeo es muy similar.

# 6. Interpretación de resultados
```{r}
rpart.plot(best_tree)
```

A simple vista, podemos ver que la variable predictora en el nodo raiz es la misma en ambos arboles, Online boarding < 4, y los valores encontrados en el nodo coinciden. Siguiendo por la rama de la izquierda, podemos ver que el siguiente corte es el mismo, se utiliza Inflight Wifi Service < 4, y se tienen los mismos valores en los nodos. Por la rama izquierda de este, se tiene el mismo corte de Inflight Wifi Service >= 1. Luego de este, empiezan a diferir. Vemos que si se utiliza la rama derecha luego del segundo corte, este cambia dado que aparecen nuevos cortes dados por otras variables predictoras.

Hacia la derecha del nodo raiz, el nodo tiene los mismos valores en ambos arboles, pero en el arbol optimizado la variable predictora que hace el corte cambia, pasa de ser Type of Travel = Personal Travel a Inflight entretaiment < 4, y los demas cortes son distintos y en mayor cantidad.

```{r}
importancia_variables_best <- best_tree$variable.importance

importancia_variables_best
```

Podemos ver que las variables predictoras más importantes son Online Boarding, Inflight Wifi Service, Seat Comfort y Ease of Online Booking. Esto se correlaciona con el grafico dado que son los primeros cortes que figuran en el arbol y son los que más cortes realizan.

```{r}
importancia_variables_basico <- tree$variable.importance

importancia_variables_basico
```

Si lo comparamos con el arbol basico, notamos que las primeras cuatro variables predictoras son las mismas. Esto quiere decir que son las que más influyen sin importar que valores de hiperparametros se utilicen. Por otro lado, notamos que en el arbol optimizado los valores de la importancia son mayores y que hay más variables que se consideran importantes.

**7. Análisis del impacto de los valores faltantes**

Para generar datasets con datos faltantes, creamos una nueva función reemplazar_na, a la cual le pasamos por parámetros los datos y el porcentaje de NA que queríamos tener. La idea de esta función era recorrer todas las columnas del conjunto de datos, excluyendo a la columna correspondien te a la variable a predecir (Satisfaction). Por cada columna, calculamos la cantidad de NA que ya tiene, la cantidad de NA que se quieren tener y la diferencia para saber cuantos más hay que agregar. Si esta diferencia es mayor a 0, entonces agregamos los NA faltantes a la columna de manera aleatoria.

```{r}
reemplazar_na <- function(data, porcentaje_na) {
  total_filas <- nrow(data)
  total_columnas <- ncol(data)  # Número total de columnas

  for (i in 1:(total_columnas - 1)) {  # Iterar hasta la anteúltima columna
    col <- colnames(data)[i]
    
    # Contar el número actual de NA en la columna
    na_existentes <- sum(is.na(data[[col]]))
    
    # Calcular cuántos NA totales debería haber para alcanzar el porcentaje deseado
    num_na_deseado <- round(porcentaje_na * total_filas)
    
    nuevos_na <- num_na_deseado - na_existentes
    
    # Solo agregar nuevos NA si el número necesario es positivo
    if (nuevos_na > 0) {
      na_indices <- sample(which(!is.na(data[[col]])), size = nuevos_na)
      data[na_indices, col] <- NA
    }
  }
  return(data)
}
```

Utilizamos esta función para generar datasets con datos con el 20%, 50% y 75% de datos faltantes.

```{r}
entrenamiento_na_20 <- reemplazar_na(entrenamiento, 0.20)
validacion_na_20 <- reemplazar_na(validacion, 0.20)
testeo_na_20 <- reemplazar_na(testeo, 0.01)

entrenamiento_na_50 <- reemplazar_na(entrenamiento, 0.50)
validacion_na_50 <- reemplazar_na(validacion, 0.50)
testeo_na_50 <- reemplazar_na(testeo, 0.50)

entrenamiento_na_75 <- reemplazar_na(entrenamiento, 0.75)
validacion_na_75 <- reemplazar_na(validacion, 0.75)
testeo_na_75 <- reemplazar_na(testeo, 0.75)
```

Para cada uno de los datasets, buscamos los hiperparámetros a través de la función creada anteriormente, para encontrar los valores de los hiperparámetros que lo optimizan.

```{r}
best_na_20 <- buscar_hiperparametros(entrenamiento = entrenamiento_na_20, validacion = validacion_na_20, valores_maxdepth = valores_maxdepth, valores_minsplit = valores_minsplit, valores_minbucket = valores_minbucket)

best_na_20$best_auc
best_na_20$best_params
```
```{r}
best_tree_na_20 <- rpart(formula = satisfaction ~ ., 
              data = entrenamiento_na_20, 
              method = "class",
              control = rpart.control(maxdepth = best_na_20$best_params[1], minsplit = best_na_20$best_params[2], minbucket = best_na_20$best_params[3], cp = 0, xval = 0))
best_predicciones <- predict(best_tree_na_20, newdata = testeo_na_20, type = "class")
auc_20 <- AUC(y_pred = best_predicciones, y_true = testeo_na_20$satisfaction)
auc_faltantes <- c(auc_20)
```
```{r}
rpart.plot(best_tree_na_20)
```
```{r}
best_na_50 <- buscar_hiperparametros(entrenamiento = entrenamiento_na_50, validacion = validacion_na_50, valores_maxdepth = valores_maxdepth, valores_minsplit = valores_minsplit, valores_minbucket = valores_minbucket)

best_na_50$best_auc
best_na_50$best_params
```
```{r}
best_tree_na_50 <- rpart(formula = satisfaction ~ ., 
              data = entrenamiento_na_50, 
              method = "class",
              control = rpart.control(maxdepth = best_na_50$best_params[1], minsplit = best_na_50$best_params[2], minbucket = best_na_50$best_params[3], cp = 0, xval = 0))
best_predicciones <- predict(best_tree_na_50, newdata = testeo_na_50, type = "class")
auc_50 <- AUC(y_pred = best_predicciones, y_true = testeo_na_50$satisfaction)
auc_faltantes <- c(auc_faltantes, auc_50)
```
```{r}
rpart.plot(best_tree_na_50)
```
```{r}
best_na_75 <- buscar_hiperparametros(entrenamiento = entrenamiento_na_75, validacion = validacion_na_75, valores_maxdepth = valores_maxdepth, valores_minsplit = valores_minsplit, valores_minbucket = valores_minbucket)

best_na_75$best_auc
best_na_75$best_params
```
```{r}
best_tree_na_75 <- rpart(formula = satisfaction ~ ., 
              data = entrenamiento_na_75, 
              method = "class",
              control = rpart.control(maxdepth = best_na_75$best_params[1], minsplit = best_na_75$best_params[2], minbucket = best_na_75$best_params[3], cp = 0, xval = 0))
best_predicciones <- predict(best_tree_na_75, newdata = testeo_na_75, type = "class")
auc_75 <- AUC(y_pred = best_predicciones, y_true = testeo_na_75$satisfaction)
auc_faltantes <- c(auc_faltantes, auc_75)
```
```{r}
rpart.plot(best_tree_na_75)
```

Pudimos observar que existe una relación inversa entre el porcentaje de datos faltantes y el AUC: mientras más datos faltantes tiene el conjunto, menor es el AUC.

```{r}
df_auc <- data.frame(
  porcentajes <- c(20, 50, 75),
  auc_faltantes
)

ggplot(df_auc, aes(x = porcentajes, y = auc_faltantes)) +
  geom_line(color = "blue") +  # Línea que conecta los puntos
  geom_point(size = 3, color = "red") +  # Puntos de AUC
  labs(title = "Relación entre AUC y Porcentaje de Datos Faltantes",
       x = "Porcentaje de Datos Faltantes",
       y = "AUC") +
  theme_minimal()
```

#8. Conclusión

A lo largo de este trabajo, modelamos arboles de decisión para poder predecir la satisfacción de un pasajero a partir de un conjunto de variables predictoras. 

Con el modelo basico, obtuvimos buenas metricas de performance antes datos nuevos, obteniendo un accuracy de 88%. Esto, con el resto de las metricas, indica que el modelo predice correctamente en la gran mayoría de las veces. Sin embargo, no es perfecto dado que, a pesar de tener una precision alta, existe un porcentaje de datos que el modelo no predice bien. En cuanto a las variables predictoras que cortan los nodos son las que más correlación tienen con la variable a predecir.

En cuanto a la optimización del modelo, notamos que para maxdepth el se tiende a tomar con el valor más grande y en minsplit y minbucket se tiende a tomar el valor más chico. Esto tiene sentido ya que, a más profundida, más cortes se pueden tener y mejor adaptar el arbol a los valores de entrenamiento; a menor minsplit, se necesita una menor cantidad de observaciones para dividir un nodo, por lo que se podra dividir más facilmente y tener aun más diviciones; a menor minbucket, se necesitaran menos observaciones para tener un hoja terminal, por lo que se tendran más hojas termiales. Esto lleva a que el arbol se pueda adaptar mejor a los datos. Al graficar como varia el AUC dependiendo de cada variable, pudimos afirmar esta idea dado que maxdepth tiene una relación directamente proporcional al AUC y minsplit y minbucket tienen un relacion inversamente proporcional al AUC.

Como la optimización se basa en el AUC de validación, los resultados que arroje este pueden llegar a estar overfiteados al mismo. Sin embargo, al calcular el AUC sobre datos nuevos con los mejores parametros, notamos valores muy similares en la metrica de performance, y más alta que en el modelo basico.

En cuanto a la optimización del modelo cuando se presetan datos faltantes, npudimos observar que a medida que aumenta el porcentaje de datos faltantes, disminuye el AUC. Esto tiene sentido porque al tener una menor cantidad de datos el modelo tiene cada vez menos información con la que trabajar, empeorando e arbol de decision.

Relacionado a esto, notamos que cuando se presentan los datos faltantes no cumplen tanto con lo dicho anteriormente sobre los hiperparametros. Con esto nos referimos que el maxdepth no necesariamente es el mas grande, por ejemplo con 20% de datos faltantes se utiliza un maxdepth de 9.

Aunque los modelos que se obtuvieron tienen metricas de performance muy favorables, se podría agregar al analisis implementar ingeniería de atributos para ver como estas influyen en los modelos y si mejoran mucho más el AUC o queda estancado en cierto valor.

[^1]: https://www.kaggle.com/datasets/teejmahal20/airline-passenger-satisfaction